{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 4: Redis Exercises - Key-Value Store\n",
        "\n",
        "## üéØ Objectives\n",
        "- Understand Redis data structures\n",
        "- Implement caching strategies\n",
        "- Practice session management\n",
        "- Learn rate limiting techniques\n",
        "- Optimize performance with Redis\n",
        "\n",
        "## üìã Prerequisites\n",
        "- Complete Lab 1 (Setup & Connections)\n",
        "- Redis container is running\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Redis connected successfully!\n",
            "Redis version: 7.2.10\n"
          ]
        }
      ],
      "source": [
        "import redis\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Redis connection\n",
        "redis_client = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)\n",
        "\n",
        "# Test connection\n",
        "redis_client.ping()\n",
        "print(\"‚úÖ Redis connected successfully!\")\n",
        "print(f\"Redis version: {redis_client.info('server')['redis_version']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 1: Basic Operations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: John Doe\n",
            "Session: active\n",
            "Session TTL: 3600 seconds\n",
            "Product: {'name': 'iPhone 15 Pro', 'price': '25000000', 'category': 'electronics'}\n",
            "Recent products: ['prod_003', 'prod_002', 'prod_001']\n",
            "Electronics products: {'prod_002', 'prod_001', 'prod_003'}\n",
            "‚úÖ Basic operations completed!\n"
          ]
        }
      ],
      "source": [
        "# Basic string operations\n",
        "redis_client.set(\"user:001\", \"John Doe\")\n",
        "redis_client.setex(\"session:001\", 3600, \"active\")  # Expires in 1 hour\n",
        "\n",
        "# Get values\n",
        "user = redis_client.get(\"user:001\")\n",
        "session = redis_client.get(\"session:001\")\n",
        "ttl = redis_client.ttl(\"session:001\")\n",
        "\n",
        "print(f\"User: {user}\")\n",
        "print(f\"Session: {session}\")\n",
        "print(f\"Session TTL: {ttl} seconds\")\n",
        "\n",
        "# Hash operations\n",
        "redis_client.hset(\"product:001\", mapping={\n",
        "    \"name\": \"iPhone 15 Pro\",\n",
        "    \"price\": \"25000000\",\n",
        "    \"category\": \"electronics\"\n",
        "})\n",
        "\n",
        "product = redis_client.hgetall(\"product:001\")\n",
        "print(f\"Product: {product}\")\n",
        "\n",
        "# List operations\n",
        "redis_client.lpush(\"recent_products\", \"prod_001\", \"prod_002\", \"prod_003\")\n",
        "recent = redis_client.lrange(\"recent_products\", 0, -1)\n",
        "print(f\"Recent products: {recent}\")\n",
        "\n",
        "# Set operations\n",
        "redis_client.sadd(\"category:electronics\", \"prod_001\", \"prod_002\", \"prod_003\")\n",
        "electronics = redis_client.smembers(\"category:electronics\")\n",
        "print(f\"Electronics products: {electronics}\")\n",
        "\n",
        "print(\"‚úÖ Basic operations completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 2: Caching Strategy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cached product: {'productId': 'prod_001', 'name': 'iPhone 15 Pro', 'price': 25000000, 'category': 'electronics'}\n",
            "Cached session exists: 1\n",
            "‚úÖ Caching strategy implemented!\n"
          ]
        }
      ],
      "source": [
        "class CacheService:\n",
        "    def __init__(self, redis_client):\n",
        "        self.redis = redis_client\n",
        "    \n",
        "    def cache_product(self, product_id, product_data, ttl=1800):\n",
        "        \"\"\"Cache product data with TTL\"\"\"\n",
        "        key = f\"product:{product_id}\"\n",
        "        self.redis.setex(key, ttl, json.dumps(product_data))\n",
        "        return True\n",
        "    \n",
        "    def get_cached_product(self, product_id):\n",
        "        \"\"\"Get cached product data\"\"\"\n",
        "        key = f\"product:{product_id}\"\n",
        "        data = self.redis.get(key)\n",
        "        return json.loads(data) if data else None\n",
        "    \n",
        "    def cache_user_session(self, user_id, session_data, ttl=3600):\n",
        "        \"\"\"Cache user session\"\"\"\n",
        "        key = f\"session:{user_id}\"\n",
        "        self.redis.setex(key, ttl, json.dumps(session_data))\n",
        "        return True\n",
        "    \n",
        "    def invalidate_cache(self, pattern):\n",
        "        \"\"\"Invalidate cache by pattern\"\"\"\n",
        "        keys = self.redis.keys(pattern)\n",
        "        if keys:\n",
        "            return self.redis.delete(*keys)\n",
        "        return 0\n",
        "\n",
        "# Initialize cache service\n",
        "cache_service = CacheService(redis_client)\n",
        "\n",
        "# Cache sample product\n",
        "product_data = {\n",
        "    \"productId\": \"prod_001\",\n",
        "    \"name\": \"iPhone 15 Pro\",\n",
        "    \"price\": 25000000,\n",
        "    \"category\": \"electronics\"\n",
        "}\n",
        "\n",
        "cache_service.cache_product(\"prod_001\", product_data)\n",
        "cached_product = cache_service.get_cached_product(\"prod_001\")\n",
        "print(f\"Cached product: {cached_product}\")\n",
        "\n",
        "# Cache user session\n",
        "session_data = {\n",
        "    \"userId\": \"user_001\",\n",
        "    \"cart\": [\"prod_001\", \"prod_002\"],\n",
        "    \"lastActivity\": datetime.utcnow().isoformat()\n",
        "}\n",
        "\n",
        "cache_service.cache_user_session(\"user_001\", session_data)\n",
        "cached_session = cache_service.get_cached_product(\"user_001\")  # This will be None\n",
        "print(f\"Cached session exists: {redis_client.exists('session:user_001')}\")\n",
        "\n",
        "print(\"‚úÖ Caching strategy implemented!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 3: Rate Limiting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing rate limiting for user user_001 (limit: 5)\n",
            "Request 1: ‚úÖ Allowed (Remaining: 4)\n",
            "Request 2: ‚úÖ Allowed (Remaining: 3)\n",
            "Request 3: ‚úÖ Allowed (Remaining: 2)\n",
            "Request 4: ‚úÖ Allowed (Remaining: 1)\n",
            "Request 5: ‚úÖ Allowed (Remaining: 0)\n",
            "Request 6: ‚ùå Blocked (Remaining: 0)\n",
            "Request 7: ‚ùå Blocked (Remaining: 0)\n",
            "‚úÖ Rate limiting implemented!\n"
          ]
        }
      ],
      "source": [
        "class RateLimiter:\n",
        "    def __init__(self, redis_client):\n",
        "        self.redis = redis_client\n",
        "    \n",
        "    def is_allowed(self, user_id, limit=100, window=3600):\n",
        "        \"\"\"Check if user is within rate limit\"\"\"\n",
        "        key = f\"rate_limit:{user_id}\"\n",
        "        current = self.redis.incr(key)\n",
        "        \n",
        "        if current == 1:\n",
        "            self.redis.expire(key, window)\n",
        "        \n",
        "        return current <= limit\n",
        "    \n",
        "    def get_remaining_requests(self, user_id, limit=100):\n",
        "        \"\"\"Get remaining requests for user\"\"\"\n",
        "        key = f\"rate_limit:{user_id}\"\n",
        "        current = self.redis.get(key)\n",
        "        if current is None:\n",
        "            return limit\n",
        "        return max(0, limit - int(current))\n",
        "\n",
        "# Initialize rate limiter\n",
        "rate_limiter = RateLimiter(redis_client)\n",
        "\n",
        "# Test rate limiting\n",
        "user_id = \"user_001\"\n",
        "limit = 5\n",
        "\n",
        "print(f\"Testing rate limiting for user {user_id} (limit: {limit})\")\n",
        "\n",
        "for i in range(7):\n",
        "    allowed = rate_limiter.is_allowed(user_id, limit, 60)  # 60 second window\n",
        "    remaining = rate_limiter.get_remaining_requests(user_id, limit)\n",
        "    print(f\"Request {i+1}: {'‚úÖ Allowed' if allowed else '‚ùå Blocked'} (Remaining: {remaining})\")\n",
        "\n",
        "print(\"‚úÖ Rate limiting implemented!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 4: Performance Benchmarking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Running Redis performance benchmark...\n",
            "\n",
            "üìä Performance Results:\n",
            "--------------------------------------------------\n",
            "SET      |     5415 ops/sec | 0.1847s\n",
            "GET      |     8115 ops/sec | 0.1232s\n",
            "HSET     |     7236 ops/sec | 0.1382s\n",
            "HGET     |     7857 ops/sec | 0.1273s\n",
            "LPUSH    |     7241 ops/sec | 0.1381s\n",
            "LRANGE   |      860 ops/sec | 1.1633s\n",
            "SADD     |     6485 ops/sec | 0.1542s\n",
            "SMEMBERS |     6654 ops/sec | 0.1503s\n",
            "\n",
            "‚úÖ Performance benchmarking completed!\n"
          ]
        }
      ],
      "source": [
        "# Performance benchmarking\n",
        "def benchmark_redis_operations():\n",
        "    \"\"\"Benchmark different Redis operations\"\"\"\n",
        "    operations = {\n",
        "        \"SET\": lambda: redis_client.set(\"test:key\", \"test_value\"),\n",
        "        \"GET\": lambda: redis_client.get(\"test:key\"),\n",
        "        \"HSET\": lambda: redis_client.hset(\"test:hash\", \"field\", \"value\"),\n",
        "        \"HGET\": lambda: redis_client.hget(\"test:hash\", \"field\"),\n",
        "        \"LPUSH\": lambda: redis_client.lpush(\"test:list\", \"item\"),\n",
        "        \"LRANGE\": lambda: redis_client.lrange(\"test:list\", 0, -1),\n",
        "        \"SADD\": lambda: redis_client.sadd(\"test:set\", \"member\"),\n",
        "        \"SMEMBERS\": lambda: redis_client.smembers(\"test:set\")\n",
        "    }\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    for op_name, op_func in operations.items():\n",
        "        start_time = time.time()\n",
        "        for _ in range(1000):  # Run 1000 operations\n",
        "            op_func()\n",
        "        end_time = time.time()\n",
        "        \n",
        "        duration = end_time - start_time\n",
        "        ops_per_sec = 1000 / duration\n",
        "        results[op_name] = {\n",
        "            \"duration\": duration,\n",
        "            \"ops_per_sec\": ops_per_sec\n",
        "        }\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Run benchmark\n",
        "print(\"üöÄ Running Redis performance benchmark...\")\n",
        "benchmark_results = benchmark_redis_operations()\n",
        "\n",
        "# Display results\n",
        "print(\"\\nüìä Performance Results:\")\n",
        "print(\"-\" * 50)\n",
        "for op, metrics in benchmark_results.items():\n",
        "    print(f\"{op:8} | {metrics['ops_per_sec']:8.0f} ops/sec | {metrics['duration']:.4f}s\")\n",
        "\n",
        "# Cleanup test keys\n",
        "redis_client.delete(\"test:key\", \"test:hash\", \"test:list\", \"test:set\")\n",
        "\n",
        "print(\"\\n‚úÖ Performance benchmarking completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéì Student Exercises - Advanced Redis Practice\n",
        "\n",
        "### Exercise 5: Async Redis Queue Implementation\n",
        "**Objective**: Build asynchronous task queue system using Redis\n",
        "\n",
        "**Scenario**: You need to build a **Background Job Processing System** for an e-commerce platform with:\n",
        "- Order processing queue\n",
        "- Email notification queue\n",
        "- Image processing queue\n",
        "- Analytics data processing queue\n",
        "\n",
        "**Tasks**:\n",
        "1. **Implement async Redis queue**:\n",
        "   - Create job queue using Redis Lists\n",
        "   - Implement job producer and consumer\n",
        "   - Add job priority handling\n",
        "   - Implement job retry mechanism\n",
        "\n",
        "2. **Build queue management features**:\n",
        "   - Job status tracking\n",
        "   - Queue monitoring dashboard\n",
        "   - Failed job handling\n",
        "   - Queue statistics\n",
        "\n",
        "3. **Implement advanced queue patterns**:\n",
        "   - Delayed job execution\n",
        "   - Job scheduling\n",
        "   - Dead letter queue\n",
        "   - Job batching\n",
        "\n",
        "**Requirements**:\n",
        "- Use Redis Lists for queue implementation\n",
        "- Implement proper error handling\n",
        "- Add job serialization/deserialization\n",
        "- Include monitoring and logging\n",
        "- Handle concurrent job processing\n",
        "\n",
        "---\n",
        "\n",
        "### Exercise 6: Real-time Analytics with Redis Streams\n",
        "**Objective**: Build real-time analytics system using Redis Streams\n",
        "\n",
        "**Scenario**: Build a **Real-time E-commerce Analytics Platform** with:\n",
        "- Live user activity tracking\n",
        "- Real-time sales analytics\n",
        "- Live inventory monitoring\n",
        "- Real-time recommendation updates\n",
        "\n",
        "**Tasks**:\n",
        "1. **Implement Redis Streams**:\n",
        "   - Create event streams for user activities\n",
        "   - Implement stream consumers\n",
        "   - Add stream processing logic\n",
        "   - Handle stream persistence\n",
        "\n",
        "2. **Build analytics features**:\n",
        "   - Real-time user behavior tracking\n",
        "   - Live sales dashboard\n",
        "   - Inventory alerts\n",
        "   - Performance metrics\n",
        "\n",
        "3. **Create monitoring system**:\n",
        "   - Stream health monitoring\n",
        "   - Consumer lag tracking\n",
        "   - Performance metrics\n",
        "   - Alert system\n",
        "\n",
        "**Requirements**:\n",
        "- Use Redis Streams for event processing\n",
        "- Implement proper stream management\n",
        "- Add real-time data visualization\n",
        "- Handle high-volume data streams\n",
        "- Include fault tolerance\n",
        "\n",
        "---\n",
        "\n",
        "### Exercise 7: Distributed Caching and Session Management\n",
        "**Objective**: Implement distributed caching and session management system\n",
        "\n",
        "**Scenario**: Build a **Scalable Session Management System** for a multi-server e-commerce platform with:\n",
        "- Distributed session storage\n",
        "- Session replication\n",
        "- Cache invalidation strategies\n",
        "- User preference caching\n",
        "\n",
        "**Tasks**:\n",
        "1. **Implement distributed session management**:\n",
        "   - Multi-server session sharing\n",
        "   - Session replication strategies\n",
        "   - Session failover handling\n",
        "   - Session cleanup automation\n",
        "\n",
        "2. **Build advanced caching strategies**:\n",
        "   - Cache-aside pattern\n",
        "   - Write-through caching\n",
        "   - Write-behind caching\n",
        "   - Cache warming strategies\n",
        "\n",
        "3. **Create cache management tools**:\n",
        "   - Cache invalidation system\n",
        "   - Cache performance monitoring\n",
        "   - Cache hit/miss analytics\n",
        "   - Cache optimization tools\n",
        "\n",
        "**Requirements**:\n",
        "- Use Redis Cluster for distributed caching\n",
        "- Implement proper session management\n",
        "- Add cache invalidation strategies\n",
        "- Include performance monitoring\n",
        "- Handle cache consistency\n",
        "\n",
        "---\n",
        "\n",
        "### Exercise 8: Redis Pub/Sub and Event-Driven Architecture\n",
        "**Objective**: Build event-driven architecture using Redis Pub/Sub\n",
        "\n",
        "**Scenario**: Build an **Event-Driven E-commerce System** with:\n",
        "- Real-time notifications\n",
        "- Event-driven microservices\n",
        "- Real-time inventory updates\n",
        "- Live order status updates\n",
        "\n",
        "**Tasks**:\n",
        "1. **Implement Redis Pub/Sub**:\n",
        "   - Create event publishers\n",
        "   - Implement event subscribers\n",
        "   - Add event filtering\n",
        "   - Handle message persistence\n",
        "\n",
        "2. **Build event-driven features**:\n",
        "   - Real-time notifications\n",
        "   - Inventory synchronization\n",
        "   - Order status updates\n",
        "   - User activity broadcasting\n",
        "\n",
        "3. **Create event management system**:\n",
        "   - Event routing\n",
        "   - Event filtering\n",
        "   - Event persistence\n",
        "   - Event replay capability\n",
        "\n",
        "**Requirements**:\n",
        "- Use Redis Pub/Sub for messaging\n",
        "- Implement proper event handling\n",
        "- Add event persistence\n",
        "- Include error handling\n",
        "- Handle message ordering\n",
        "\n",
        "---\n",
        "\n",
        "### Exercise 9: Redis Performance Optimization and Monitoring\n",
        "**Objective**: Optimize Redis performance and implement comprehensive monitoring\n",
        "\n",
        "**Tasks**:\n",
        "1. **Implement performance optimization**:\n",
        "   - Memory optimization strategies\n",
        "   - Connection pooling\n",
        "   - Pipeline operations\n",
        "   - Lua scripting for complex operations\n",
        "\n",
        "2. **Build monitoring system**:\n",
        "   - Performance metrics collection\n",
        "   - Memory usage monitoring\n",
        "   - Connection monitoring\n",
        "   - Query performance analysis\n",
        "\n",
        "3. **Create optimization tools**:\n",
        "   - Performance benchmarking\n",
        "   - Memory usage analysis\n",
        "   - Query optimization\n",
        "   - Capacity planning\n",
        "\n",
        "**Requirements**:\n",
        "- Use Redis performance tuning techniques\n",
        "- Implement comprehensive monitoring\n",
        "- Add performance benchmarking\n",
        "- Include capacity planning\n",
        "- Handle performance bottlenecks\n",
        "\n",
        "---\n",
        "\n",
        "### Exercise 10: Redis Security and Data Protection\n",
        "**Objective**: Implement security measures and data protection for Redis\n",
        "\n",
        "**Scenario**: Secure a **Production Redis System** with:\n",
        "- Data encryption\n",
        "- Access control\n",
        "- Audit logging\n",
        "- Data backup and recovery\n",
        "\n",
        "**Tasks**:\n",
        "1. **Implement security measures**:\n",
        "   - Redis AUTH configuration\n",
        "   - ACL (Access Control Lists)\n",
        "   - Network security\n",
        "   - Data encryption\n",
        "\n",
        "2. **Build data protection features**:\n",
        "   - Data backup strategies\n",
        "   - Disaster recovery\n",
        "   - Data retention policies\n",
        "   - Compliance monitoring\n",
        "\n",
        "3. **Create security monitoring**:\n",
        "   - Access logging\n",
        "   - Security alerts\n",
        "   - Audit trails\n",
        "   - Compliance reporting\n",
        "\n",
        "**Requirements**:\n",
        "- Implement Redis security best practices\n",
        "- Add comprehensive logging\n",
        "- Include backup and recovery\n",
        "- Handle security compliance\n",
        "- Monitor security events\n",
        "\n",
        "---\n",
        "\n",
        "## üìù Submission Guidelines\n",
        "\n",
        "### For Each Exercise:\n",
        "1. **Complete all tasks** as specified\n",
        "2. **Include proper documentation** and comments\n",
        "3. **Test your code** with sample data\n",
        "4. **Handle errors** appropriately\n",
        "5. **Optimize performance** where possible\n",
        "\n",
        "### Code Quality Requirements:\n",
        "- Follow Python best practices\n",
        "- Use meaningful variable names\n",
        "- Include type hints where appropriate\n",
        "- Write clean, readable code\n",
        "- Add comprehensive comments\n",
        "\n",
        "### Testing Requirements:\n",
        "- Test with various Redis scenarios\n",
        "- Test edge cases and error conditions\n",
        "- Verify expected outputs\n",
        "- Include performance benchmarks\n",
        "\n",
        "### Documentation Requirements:\n",
        "- Explain your Redis usage patterns\n",
        "- Document performance optimizations\n",
        "- Include usage examples\n",
        "- Provide performance analysis\n",
        "\n",
        "---\n",
        "\n",
        "## üèÜ Bonus Challenges\n",
        "\n",
        "### Challenge 1: Redis Cluster Implementation\n",
        "Implement a Redis Cluster setup with automatic failover and data sharding.\n",
        "\n",
        "### Challenge 2: Redis with Machine Learning\n",
        "Use Redis for real-time machine learning model serving and feature store.\n",
        "\n",
        "### Challenge 3: Redis as a Database\n",
        "Build a complete application using Redis as the primary database with proper data modeling.\n",
        "\n",
        "### Challenge 4: Redis Integration with Cloud Services\n",
        "Integrate Redis with cloud services like AWS ElastiCache, Azure Cache, or Google Cloud Memorystore.\n",
        "\n",
        "---\n",
        "\n",
        "**Good luck with your Redis journey! üöÄ**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 5: Async Redis Queue Implementation - Starter Code\n",
        "# Build asynchronous task queue system using Redis\n",
        "\n",
        "import asyncio\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "from typing import Dict, Any, Optional\n",
        "\n",
        "class AsyncRedisQueue:\n",
        "    def __init__(self, redis_client, queue_name: str = \"default\"):\n",
        "        self.redis = redis_client\n",
        "        self.queue_name = queue_name\n",
        "        self.processing_queue = f\"{queue_name}:processing\"\n",
        "        self.failed_queue = f\"{queue_name}:failed\"\n",
        "    \n",
        "    def enqueue_job(self, job_data: Dict[str, Any], priority: int = 0) -> str:\n",
        "        \"\"\"\n",
        "        Add a job to the queue\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def dequeue_job(self, timeout: int = 0) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Get a job from the queue\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def mark_job_completed(self, job_id: str) -> bool:\n",
        "        \"\"\"\n",
        "        Mark a job as completed\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def mark_job_failed(self, job_id: str, error: str) -> bool:\n",
        "        \"\"\"\n",
        "        Mark a job as failed\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def get_queue_stats(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Get queue statistics\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "class JobProcessor:\n",
        "    def __init__(self, queue: AsyncRedisQueue):\n",
        "        self.queue = queue\n",
        "        self.running = False\n",
        "    \n",
        "    async def start_processing(self):\n",
        "        \"\"\"\n",
        "        Start processing jobs from the queue\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    async def process_job(self, job_data: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Process a single job\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def stop_processing(self):\n",
        "        \"\"\"\n",
        "        Stop processing jobs\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "# Sample job data structure (for reference)\n",
        "sample_jobs = [\n",
        "    {\n",
        "        \"id\": \"job_001\",\n",
        "        \"type\": \"email_notification\",\n",
        "        \"data\": {\n",
        "            \"to\": \"user@example.com\",\n",
        "            \"subject\": \"Order Confirmation\",\n",
        "            \"body\": \"Your order has been confirmed\"\n",
        "        },\n",
        "        \"priority\": 1,\n",
        "        \"created_at\": datetime.now().isoformat()\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"job_002\", \n",
        "        \"type\": \"image_processing\",\n",
        "        \"data\": {\n",
        "            \"image_url\": \"https://example.com/image.jpg\",\n",
        "            \"operations\": [\"resize\", \"compress\"]\n",
        "        },\n",
        "        \"priority\": 2,\n",
        "        \"created_at\": datetime.now().isoformat()\n",
        "    }\n",
        "]\n",
        "\n",
        "# Initialize queue and processor\n",
        "queue = AsyncRedisQueue(redis_client, \"ecommerce_jobs\")\n",
        "processor = JobProcessor(queue)\n",
        "\n",
        "print(\"Exercise 5: Async Redis Queue Implementation\")\n",
        "print(\"Complete the AsyncRedisQueue and JobProcessor methods above!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 6: Real-time Analytics with Redis Streams - Starter Code\n",
        "# Build real-time analytics system using Redis Streams\n",
        "\n",
        "class RedisStreamAnalytics:\n",
        "    def __init__(self, redis_client):\n",
        "        self.redis = redis_client\n",
        "        self.stream_name = \"user_activity\"\n",
        "        self.consumer_group = \"analytics_group\"\n",
        "    \n",
        "    def add_event(self, event_type: str, user_id: str, data: Dict[str, Any]) -> str:\n",
        "        \"\"\"\n",
        "        Add an event to the stream\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def create_consumer_group(self, group_name: str, start_id: str = \"0\") -> bool:\n",
        "        \"\"\"\n",
        "        Create a consumer group for the stream\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def read_events(self, consumer_name: str, count: int = 10) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Read events from the stream\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def process_user_activity(self, events: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Process user activity events for analytics\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def get_stream_info(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Get stream information and statistics\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "class RealTimeAnalytics:\n",
        "    def __init__(self, stream_analytics: RedisStreamAnalytics):\n",
        "        self.stream_analytics = stream_analytics\n",
        "        self.metrics = {}\n",
        "    \n",
        "    def track_user_action(self, user_id: str, action: str, metadata: Dict[str, Any]):\n",
        "        \"\"\"\n",
        "        Track user action in real-time\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def get_real_time_metrics(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Get real-time analytics metrics\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def generate_alerts(self, threshold: float) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Generate alerts based on metrics\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "# Sample event data structure (for reference)\n",
        "sample_events = [\n",
        "    {\n",
        "        \"event_type\": \"page_view\",\n",
        "        \"user_id\": \"user_001\",\n",
        "        \"data\": {\n",
        "            \"page\": \"/products/iphone\",\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"session_id\": \"session_001\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"event_type\": \"purchase\",\n",
        "        \"user_id\": \"user_001\", \n",
        "        \"data\": {\n",
        "            \"product_id\": \"prod_001\",\n",
        "            \"amount\": 25000000,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# Initialize analytics system\n",
        "stream_analytics = RedisStreamAnalytics(redis_client)\n",
        "real_time_analytics = RealTimeAnalytics(stream_analytics)\n",
        "\n",
        "print(\"Exercise 6: Real-time Analytics with Redis Streams\")\n",
        "print(\"Complete the RedisStreamAnalytics and RealTimeAnalytics methods above!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 7: Distributed Caching and Session Management - Starter Code\n",
        "# Implement distributed caching and session management system\n",
        "\n",
        "class DistributedSessionManager:\n",
        "    def __init__(self, redis_client):\n",
        "        self.redis = redis_client\n",
        "        self.session_prefix = \"session:\"\n",
        "        self.user_prefix = \"user:\"\n",
        "    \n",
        "    def create_session(self, user_id: str, session_data: Dict[str, Any], ttl: int = 3600) -> str:\n",
        "        \"\"\"\n",
        "        Create a new user session\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def get_session(self, session_id: str) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Get session data by session ID\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def update_session(self, session_id: str, data: Dict[str, Any]) -> bool:\n",
        "        \"\"\"\n",
        "        Update session data\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def invalidate_session(self, session_id: str) -> bool:\n",
        "        \"\"\"\n",
        "        Invalidate a session\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def get_user_sessions(self, user_id: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Get all active sessions for a user\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "class AdvancedCacheManager:\n",
        "    def __init__(self, redis_client):\n",
        "        self.redis = redis_client\n",
        "        self.cache_prefix = \"cache:\"\n",
        "    \n",
        "    def cache_set(self, key: str, value: Any, ttl: int = 3600, strategy: str = \"cache_aside\") -> bool:\n",
        "        \"\"\"\n",
        "        Set cache with different strategies\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def cache_get(self, key: str) -> Optional[Any]:\n",
        "        \"\"\"\n",
        "        Get cache value\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def cache_invalidate_pattern(self, pattern: str) -> int:\n",
        "        \"\"\"\n",
        "        Invalidate cache by pattern\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def cache_warm_up(self, keys: List[str], data_source_func) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Warm up cache with data\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def get_cache_stats(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Get cache statistics\n",
        "        TODO: Implement this function\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "# Sample session and cache data structures (for reference)\n",
        "sample_session_data = {\n",
        "    \"user_id\": \"user_001\",\n",
        "    \"login_time\": datetime.now().isoformat(),\n",
        "    \"last_activity\": datetime.now().isoformat(),\n",
        "    \"ip_address\": \"192.168.1.100\",\n",
        "    \"user_agent\": \"Mozilla/5.0...\",\n",
        "    \"preferences\": {\n",
        "        \"theme\": \"dark\",\n",
        "        \"language\": \"en\",\n",
        "        \"notifications\": True\n",
        "    }\n",
        "}\n",
        "\n",
        "sample_cache_data = {\n",
        "    \"user_profile\": {\n",
        "        \"user_id\": \"user_001\",\n",
        "        \"name\": \"John Doe\",\n",
        "        \"email\": \"john@example.com\",\n",
        "        \"preferences\": {\"theme\": \"dark\"}\n",
        "    },\n",
        "    \"product_catalog\": {\n",
        "        \"category\": \"electronics\",\n",
        "        \"products\": [\"prod_001\", \"prod_002\", \"prod_003\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Initialize managers\n",
        "session_manager = DistributedSessionManager(redis_client)\n",
        "cache_manager = AdvancedCacheManager(redis_client)\n",
        "\n",
        "print(\"Exercise 7: Distributed Caching and Session Management\")\n",
        "print(\"Complete the DistributedSessionManager and AdvancedCacheManager methods above!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "datalab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
